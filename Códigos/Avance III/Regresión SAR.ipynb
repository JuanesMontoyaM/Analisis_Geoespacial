{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8cbc208-9c1c-48e4-9f4c-71de4633992f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION RESULTS\n",
      "------------------\n",
      "\n",
      "SUMMARY OF OUTPUT: MAXIMUM LIKELIHOOD SPATIAL LAG (METHOD = FULL)\n",
      "-----------------------------------------------------------------\n",
      "Data set            :     unknown\n",
      "Weights matrix      :       Queen\n",
      "Dependent Variable  :       count                Number of Observations:        2426\n",
      "Mean dependent var  :      1.4596                Number of Variables   :           9\n",
      "S.D. dependent var  :      1.7774                Degrees of Freedom    :        2417\n",
      "Pseudo R-squared    :      0.2938\n",
      "Spatial Pseudo R-squared:  0.1093\n",
      "Log likelihood      :  -4496.4363\n",
      "Sigma-square ML     :      2.2615                Akaike info criterion :    9010.873\n",
      "S.E of regression   :      1.5038                Schwarz criterion     :    9063.019\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     z-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT        -0.50299         0.48702        -1.03279         0.30170\n",
      "            dem_mean         0.00005         0.00016         0.31294         0.75432\n",
      "          slope_mean        -0.00721         0.00461        -1.56289         0.11808\n",
      "            twi_mean         0.18486         0.05126         3.60627         0.00031\n",
      "          dist_drain         0.00069         0.00033         2.08630         0.03695\n",
      "          dist_fault         0.00031         0.00012         2.60648         0.00915\n",
      "cov_Bosque fragmentado         0.12416         0.08696         1.42782         0.15334\n",
      "cov_Mosaico de cultivos y espacios naturales         2.90879         0.67620         4.30166         0.00002\n",
      "             W_count         0.55960         0.02512        22.27575         0.00000\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "SPATIAL LAG MODEL IMPACTS\n",
      "Impacts computed using the 'simple' method.\n",
      "            Variable         Direct        Indirect          Total\n",
      "            dem_mean         0.0000          0.0001          0.0001\n",
      "          slope_mean        -0.0072         -0.0092         -0.0164\n",
      "            twi_mean         0.1849          0.2349          0.4197\n",
      "          dist_drain         0.0007          0.0009          0.0016\n",
      "          dist_fault         0.0003          0.0004          0.0007\n",
      "cov_Bosque fragmentado         0.1242          0.1578          0.2819\n",
      "cov_Mosaico de cultivos y espacios naturales         2.9088          3.6961          6.6049\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "# Modelo de regresión para dependencia espacial tipo SAR\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "from rasterstats import zonal_stats\n",
    "from libpysal.weights import Queen\n",
    "from spreg import ML_Lag\n",
    "\n",
    "ruta_geoformas = r\"C:\\Users\\esteb\\Desktop\\GEOS\\Maestría\\2025-1S\\Análisis geoespacial\\Propuesta_geoformas\\SIG\\SHP\\Inventario_geoformas_karsticas_Dunita.shp\"\n",
    "ruta_contorno  = r\"C:\\Users\\esteb\\Desktop\\GEOS\\Maestría\\2025-1S\\Análisis geoespacial\\Propuesta_geoformas\\SIG\\SHP\\Contorno_Dunita.shp\"\n",
    "ruta_dem       = r\"C:\\Users\\esteb\\Desktop\\GEOS\\Maestría\\2025-1S\\Análisis geoespacial\\Propuesta_geoformas\\SIG\\Raster\\dem_clip.tif\"\n",
    "ruta_slope     = r\"C:\\Users\\esteb\\Desktop\\GEOS\\Maestría\\2025-1S\\Análisis geoespacial\\Propuesta_geoformas\\SIG\\Raster\\pendiente.tif\"\n",
    "ruta_twi       = r\"C:\\Users\\esteb\\Desktop\\GEOS\\Maestría\\2025-1S\\Análisis geoespacial\\Propuesta_geoformas\\SIG\\Raster\\TWI.tif\"\n",
    "ruta_cover     = r\"C:\\Users\\esteb\\Desktop\\GEOS\\Maestría\\2025-1S\\Análisis geoespacial\\Propuesta_geoformas\\SIG\\SHP\\Cobertura_final.shp\"\n",
    "ruta_drain     = r\"C:\\Users\\esteb\\Desktop\\GEOS\\Maestría\\2025-1S\\Análisis geoespacial\\Propuesta_geoformas\\SIG\\SHP\\Drenajes_clip_POT_final.shp\"\n",
    "ruta_fault     = r\"C:\\Users\\esteb\\Desktop\\GEOS\\Maestría\\2025-1S\\Análisis geoespacial\\Propuesta_geoformas\\SIG\\SHP\\Fallas_lineam.shp\"\n",
    "\n",
    "gdf_points  = gpd.read_file(ruta_geoformas)\n",
    "gdf_contour = gpd.read_file(ruta_contorno)\n",
    "\n",
    "# Generar cuadrícula de 100x100 metros\n",
    "cell_size = 100\n",
    "minx, miny, maxx, maxy = gdf_contour.total_bounds\n",
    "xs = np.arange(minx, maxx, cell_size)\n",
    "ys = np.arange(miny, maxy, cell_size)\n",
    "polygons = [box(x, y, x+cell_size, y+cell_size) for x in xs for y in ys]\n",
    "grid = gpd.GeoDataFrame({'geometry': polygons}, crs=gdf_contour.crs)\n",
    "grid = gpd.clip(grid, gdf_contour)\n",
    "\n",
    "# Conteo de puntos (variable dependiente)\n",
    "join = gpd.sjoin(grid, gdf_points, how='left', predicate='intersects')\n",
    "counts = join.groupby(join.index).size()\n",
    "grid['count'] = counts.reindex(grid.index).fillna(0).astype(int)\n",
    "\n",
    "# Extraer estadísticas zonales de los rasters\n",
    "grid['dem_mean']   = [s['mean'] if s and s['mean'] is not None else np.nan for s in zonal_stats(grid, ruta_dem,   stats=['mean'], nodata=-9999)]\n",
    "grid['slope_mean'] = [s['mean'] if s and s['mean'] is not None else np.nan for s in zonal_stats(grid, ruta_slope, stats=['mean'], nodata=-9999)]\n",
    "grid['twi_mean']   = [s['mean'] if s and s['mean'] is not None else np.nan for s in zonal_stats(grid, ruta_twi,   stats=['mean'], nodata=-9999)]\n",
    "\n",
    "# Cobertura y calcular distancias\n",
    "cov_gdf  = gpd.read_file(ruta_cover)[['d_N3_COBER','geometry']].to_crs(grid.crs)\n",
    "centroids= grid.copy()\n",
    "centroids['geometry'] = centroids.centroid\n",
    "cov_join = gpd.sjoin(centroids, cov_gdf, how='left', predicate='within')\n",
    "grid['cover'] = cov_join['d_N3_COBER'].fillna('None')\n",
    "\n",
    "drains = gpd.read_file(ruta_drain).to_crs(grid.crs)\n",
    "faults = gpd.read_file(ruta_fault).to_crs(grid.crs)\n",
    "\n",
    "union_drains = drains.geometry.union_all()\n",
    "union_faults = faults.geometry.union_all()\n",
    "\n",
    "grid['dist_drain'] = centroids.geometry.distance(union_drains)\n",
    "grid['dist_fault'] = centroids.geometry.distance(union_faults)\n",
    "\n",
    "# Limpiar datos: eliminar filas con valores nulos\n",
    "grid_clean = grid.dropna()\n",
    "\n",
    "\n",
    "# Selección de variables y preparación de matrices para el modelo SAR \n",
    "\n",
    "# Variables continuas \n",
    "vars_continuas = ['dem_mean', 'slope_mean', 'twi_mean', 'dist_drain', 'dist_fault']\n",
    "\n",
    "# Variables categóricas significativas\n",
    "vars_categoricas_sig = [\n",
    "    'Bosque fragmentado',\n",
    "    'Mosaico de cultivos y espacios naturales'\n",
    "]\n",
    "\n",
    "# Crear variables dummy solo para las coberturas seleccionadas\n",
    "df_sar = grid_clean.copy()\n",
    "df_dummies = pd.get_dummies(df_sar['cover'], prefix='cov')\n",
    "\n",
    "# Nos aseguramos de que los nombres de las columnas existan antes de usarlos\n",
    "dummies_a_usar = [f\"cov_{cat}\" for cat in vars_categoricas_sig if f\"cov_{cat}\" in df_dummies.columns]\n",
    "\n",
    "# Unir las dummies seleccionadas al GeoDataFrame\n",
    "df_sar = df_sar.join(df_dummies[dummies_a_usar])\n",
    "\n",
    "# Lista final de variables explicativas (X)\n",
    "X_vars = vars_continuas + dummies_a_usar\n",
    "\n",
    "# Preparar matrices para spreg\n",
    "y = df_sar['count'].values.reshape(-1, 1)\n",
    "X = df_sar[X_vars].astype(float).values\n",
    "\n",
    "# Ajuste del Modelo \n",
    "\n",
    "# Matriz de pesos espaciales (contigüidad tipo Queen)\n",
    "w = Queen.from_dataframe(df_sar, use_index=False)\n",
    "w.transform = 'r' # Estandarizar por filas\n",
    "\n",
    "# Ajustar el modelo SAR\n",
    "model_sar = ML_Lag(\n",
    "    y, X, w=w,\n",
    "    name_y='count',\n",
    "    name_x=X_vars,\n",
    "    name_w='Queen'\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# --- 6. Imprimir resumen del modelo ---\n",
    "print(model_sar.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba4295-3853-4fa2-a8c2-f2076232770b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
